{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ganeshmb96/OpenCV/blob/master/Predicting_Age_and_Gender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33_JIiclYy7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "f2a851e0-5715-474a-e243-ffefaf7f3a90"
      },
      "source": [
        "#Installing the dependancies\n",
        "!pip install pafy   #tool used to retrieve youtube content and metadata\n",
        "!pip install youtube_dl "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pafy\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/e8/3516f761558525b00d3eaf73744eed5c267db20650b7b660674547e3e506/pafy-0.5.4-py2.py3-none-any.whl\n",
            "Installing collected packages: pafy\n",
            "Successfully installed pafy-0.5.4\n",
            "Collecting youtube_dl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/95/956d582f6e8df5e509e1efb072a8a72a2ef8f453a06c2f55dfe6252dad70/youtube_dl-2019.9.1-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 6.7MB/s \n",
            "\u001b[?25hInstalling collected packages: youtube-dl\n",
            "Successfully installed youtube-dl-2019.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lxesFHzZMR0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8175b06a-2a9e-404c-dad4-446fb20aaf48"
      },
      "source": [
        "#Example use case of using PAFY\n",
        "import pafy\n",
        "\n",
        "url = 'https://www.youtube.com/watch?v=c07IsbSNqfI&feature=youtu.be'\n",
        "vpafy = pafy.new(url)\n",
        "print(vpafy.title)\n",
        "print(vpafy.rating)\n",
        "print(vpafy.viewcount)\n",
        "print(vpafy.author)\n",
        "print(vpafy.length)\n",
        "print(vpafy.description)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing file uploads with Postman (multipart/form-data)\n",
            "4.7124181\n",
            "36496\n",
            "Valentin Despa\n",
            "1688\n",
            "💥 Want to learn more about Postman? Check out my Postman online course. \n",
            "\n",
            "Get it for only $9.99 (limited supply!)\n",
            "http://bit.ly/2UmrlAC\n",
            "\n",
            "___\n",
            "\n",
            "// A B O U T  T H I S  V I D E O\n",
            "\n",
            "I will show you how to debug an upload script and demonstrate it with a tool called Postman that can make requests encoded as \"multipart/form-data\" so that you can send also a file.\n",
            "\n",
            "After this, we will go even further and write tests and begin automating the process.\n",
            "\n",
            "Here is the Git repository containing the files used in this tutorial:\n",
            "https://github.com/vdespa/postman-testing-file-uploads\n",
            "\n",
            "___\n",
            "\n",
            "// I  H A V E  A  Q U E S T I O N!\n",
            "\n",
            "I do my best to answer all comments here on YouTube but I cannot make any guarantees.\n",
            "\n",
            "If you have a question, it is best to ask your question on the Postman User Group on Facebook or on the Postman Community (links below). \n",
            "\n",
            "If you have purchased the Postman online course, please use the Q&A section or send me a message on Udemy. \n",
            "\n",
            "Please do not email me or contact me on other channels as I might not be able to answer. Sorry!\n",
            "\n",
            "___\n",
            "\n",
            "// I  H A V E  A  V I D E O  I D E A\n",
            "\n",
            "Do you want me to create a video on a specific topic? Just fill out the form below:\n",
            "\n",
            "https://forms.gle/uWEzXFQ2viJtZtvZ7\n",
            "\n",
            "___\n",
            "\n",
            "// P L A Y L I S T S\n",
            "\n",
            "Collection of video tutorials:\n",
            "\n",
            "▸ Learn Postman | http://bit.ly/2CFaf70\n",
            "\n",
            "▸ Postman Crash Course | http://bit.ly/2YwEBBT\n",
            "\n",
            "▸ Postman Tips & Tricks | http://bit.ly/2JLkXyU\n",
            "\n",
            "___\n",
            "\n",
            "// F R E E  R E S O U R C E S \n",
            "\n",
            "▸▸▸ DOWNLOAD the FREE Postman Quick Reference Guide\n",
            "http://bit.ly/postman-quick-reference-yt\n",
            "\n",
            "▸▸▸ JOIN the Postman User Group on Facebook\n",
            "http://bit.ly/2OutAMZ\n",
            "\n",
            "▸▸▸ OFFICIAL Postman community forum\n",
            "https://community.getpostman.com/\n",
            "\n",
            "___\n",
            "\n",
            "// IMPRINT\n",
            "\n",
            "https://vdespa.de/imprint\n",
            "\n",
            "___\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTNFkSNKZ1vj",
        "colab_type": "text"
      },
      "source": [
        "**Steps to follow :**\n",
        "  1)Get the video URL from YouTube. \n",
        "  2)Face detection with Haar cascades \n",
        "  3)Gender Recognition with CNN \n",
        "Age Recognition with CNN\n",
        "\n",
        "> Age Recognition with CNN\n",
        "\n",
        "\n",
        "  1.Get a video URL from YouTube:\n",
        "   Get the Youtube video URL and try to get the attributes of the video using pafy as explained above.\n",
        "2. Face detection with Haar cascades :\n",
        "This is a part most of us at least have heard of. OpenCV/JavaCV provide direct methods to import Haar-cascades and use them to detect faces. I will not be explaining this part in deep. You guys can refer to my previous article to know more about face detection using OpenCV.\n",
        "3. Gender Recognition with CNN:\n",
        "Gender recognition using OpenCV's fisherfaces implementation is quite popular and some of you may have tried or read about it also. But, in this example, I will be using a different approach to recognize gender. This method was introduced by two Israel researchers, Gil Levi and Tal Hassner in 2015. I have used the CNN models trained by them in this example. We are going to use the OpenCV’s dnn package which stands for “Deep Neural Networks”.\n",
        "In the dnn package, OpenCV has provided a class called Net which can be used to populate a neural network. Furthermore, these packages support importing neural network models from well known deep learning frameworks like caffe, tensorflow and torch. The researchers I had mentioned above have published their CNN models as caffe models. Therefore, we will be using the CaffeImporter import that model into our application."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN5TmQw4ZnhO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "7d104dff-b69c-44d8-aa54-01659fb7f5d0"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pafy\n",
        "#url of the video to predict Age and gender\n",
        "url = 'https://www.youtube.com/watch?v=c07IsbSNqfI&feature=youtu.be'\n",
        "vPafy = pafy.new(url)\n",
        "play = vPafy.getbest(preftype=\"mp4\") \n",
        "cap = cv2.VideoCapture(play.url)\n",
        "\n",
        "cap.set(3, 480) #set width of the frame\n",
        "cap.set(4, 640) #set height of the frame\n",
        "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
        "age_list = ['(0, 2)', '(4, 6)', '(8, 12)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
        "gender_list = ['Male', 'Female']\n",
        "\n",
        "def load_caffe_models():\n",
        "  age_net = cv2.dnn.readNetFromCaffe('deploy_age.prototxt', 'age_net.caffemodel')\n",
        "  gender_net = cv2.dnn.readNetFromCaffe('deploy_gender.prototxt', 'gender_net.caffemodel')\n",
        "  return(age_net, gender_net)\n",
        "\n",
        "def video_detector(age_net, gender_net):\n",
        "  font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "  while True:\n",
        "    ret, image = cap.read()\n",
        "       \n",
        "  face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
        "  if(len(faces)>0):\n",
        "    print(\"Found {} faces\".format(str(len(faces))))\n",
        "  for (x, y, w, h )in faces:\n",
        "    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
        "#Get Face \n",
        "    face_img = image[y:y+h, h:h+w].copy()\n",
        "    blob = cv2.dnn.blobFromImage(face_img, 1, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
        "#Predict Gender\n",
        "    gender_net.setInput(blob)\n",
        "    gender_preds = gender_net.forward()\n",
        "    gender = gender_list[gender_preds[0].argmax()]\n",
        "    print(\"Gender : \" + gender)\n",
        "#Predict Age\n",
        "    age_net.setInput(blob)\n",
        "    age_preds = age_net.forward()\n",
        "    age = age_list[age_preds[0].argmax()]\n",
        "    print(\"Age Range: \" + age)\n",
        "\n",
        "    overlay_text = \"%s %s\" % (gender, age)\n",
        "    cv2.putText(image, overlay_text, (x, y), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "    cv2.imshow('frame', image)  \n",
        "#0xFF is a hexadecimal constant which is 11111111 in binary.\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
        "      break\n",
        "    \n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "  age_net, gender_net = load_caffe_models()\n",
        "  video_detector(age_net, gender_net)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-2dce35d21d12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mage_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_caffe_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0mvideo_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-2dce35d21d12>\u001b[0m in \u001b[0;36mload_caffe_models\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_caffe_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mage_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNetFromCaffe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'deploy_age.prototxt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'age_net.caffemodel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mgender_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNetFromCaffe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'deploy_gender.prototxt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gender_net.caffemodel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(3.4.3) /io/opencv/modules/dnn/src/caffe/caffe_io.cpp:1121: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"deploy_age.prototxt\" in function 'ReadProtoFromTextFile'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mPBneFKauvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}